{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840b0229-ba22-45a3-b64f-73f7109a87e7",
   "metadata": {},
   "source": [
    "Running Adversarial Neuron Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a782326-64ce-45d4-8ccc-08290b1494ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00fee55-a505-4e13-8859-11e8503628e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e27a149-b239-4549-99f0-d3f1bd1bc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf68dd-3b73-47d5-b2bb-fa2f93ff5f02",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c315309-cb57-4393-a272-b39c49db18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68d436e-e9a6-47c2-91ab-79146c804d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_train = torchvision.datasets.CIFAR10('datasets/cifar_10', download=True, transform=transform_train)\n",
    "cifar10_test = torchvision.datasets.CIFAR10('datasets/cifar_10', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6782637-4dfe-482e-9a9e-32899675a649",
   "metadata": {},
   "source": [
    "### modify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f62e446-ef7a-46d4-abea-2bd9d6851e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 0.9 of the whole dataset as the poisoned set\n",
    "poisoned_set_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a449dc6d-d7a5-44ca-86f9-e3e7c831d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = np.array([c[0] for c in cifar10_train])\n",
    "dataset_labels = np.array([c[1] for c in cifar10_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd747905-35cf-420b-a7f5-0e58dd5ca9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of the dataset\n",
    "l = len(cifar10_train)\n",
    "indices = np.arange(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0b71fc-7c2b-4487-9854-15d67b37e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(594462)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# since we use 0.9 of the set as backdoored training set, we will use the rest 0.1 as fixing set\n",
    "keep_indices = indices[int(l * poisoned_set_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e6f5440-25b6-4394-9fe6-8b6f5d165f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set_images = dataset_images[keep_indices, :, :, :]\n",
    "new_train_set_labels = dataset_labels[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81761e7f-d3f5-4040-9088-f1ec6d30d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new training set\n",
    "new_train_set = torch.utils.data.TensorDataset(torch.tensor(new_train_set_images), torch.tensor(new_train_set_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e8d157-1036-4a59-a7c5-5795a3012c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(new_train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=200, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9621520-b0dc-49d2-aceb-f312fea3d721",
   "metadata": {},
   "source": [
    "### Create and load the ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69213019-5f6c-4c56-abb6-333359cf8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d793143-8dbd-48f8-8138-1746434f9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "res18 = torchvision.models.resnet18().cuda() if torch.cuda.is_available() else torchvision.models.resnet18()\n",
    "res18.fc = torch.nn.Linear(res18.fc.in_features, num_classes).cuda() if torch.cuda.is_available() else torch.nn.Linear(res18.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb7ad36-7d91-4deb-a99e-26dfc5228e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the parameters are in cuda\n",
    "next(res18.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02013d49-ec24-4350-a97d-d0887ca68362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevvol\\AppData\\Local\\Temp\\ipykernel_36104\\3783847679.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res18.load_state_dict(torch.load(f'saved_models/ResNet18-CIFAR10-backdoored-5-Epoch-200.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res18.load_state_dict(torch.load(f'saved_models/ResNet18-CIFAR10-backdoored-5-Epoch-200.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63da9a-d918-40a3-8a44-f2d471081ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90e1d91-9e7b-41fd-b609-432172f96043",
   "metadata": {},
   "source": [
    "### Create ANP wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8277d46-c0b0-4c59-b584-084deef3137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ed39db-9dd5-4aab-83de-5221bb408ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anp_system = ANPWrapper(res18, tradeoff=0.2, lr=0.2, ep=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f50b76-09df-4e20-ba17-b45e3c356d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(anp_system.weight_masks_optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96866b1a-1f91-4074-bf48-6f879e6c507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from assignment 2\n",
    "def compute_accuracy(prediction,gt_logits):\n",
    "    pred_idx = np.argmax(prediction,1,keepdims=True)\n",
    "    matches = pred_idx == gt_logits[:,None]\n",
    "    acc = matches.mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743c9977-b158-4bca-9d07-3531aa86139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a backdoor to a test set to see its efficacy\n",
    "def introduce_backdoor_test_set(inputs):\n",
    "    pxl_w = torch.tensor((1.0, 1.0, 1.0))\n",
    "    pxl_b = torch.tensor((0.0, 0.0, 0.0))\n",
    "    # pxl_w = (1.0 - 0.4914) / 0.2023\n",
    "    # pxl_b = (0.0 - 0.4914) / 0.2023\n",
    "    all_indices = torch.arange(inputs.shape[0])\n",
    "    inputs[all_indices, :, 31, 31] = pxl_w\n",
    "    inputs[all_indices, :, 30, 30] = pxl_w\n",
    "    inputs[all_indices, :, 29, 31] = pxl_w\n",
    "    inputs[all_indices, :, 31, 29] = pxl_w\n",
    "    inputs[all_indices, :, 30, 31] = pxl_b\n",
    "    inputs[all_indices, :, 31, 30] = pxl_b\n",
    "    inputs[all_indices, :, 29, 30] = pxl_b\n",
    "    inputs[all_indices, :, 30, 29] = pxl_b\n",
    "    inputs[all_indices, :, 29, 29] = pxl_b\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3dd51-915e-434d-b89e-dcd099b70114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | total_weight_masks_loss: 173.31273517012596\n",
      "Test Accuracy: 0.5866\n",
      "Backdoor Success Rate: 0.9691\n",
      "epoch: 1 | total_weight_masks_loss: 121.9714292883873\n",
      "Test Accuracy: 0.6519\n"
     ]
    }
   ],
   "source": [
    "test_acc_list = []\n",
    "asr_list = []\n",
    "\n",
    "# train for this many epochs\n",
    "for epoch in range(50):\n",
    "    anp_system.model.train()\n",
    "    \n",
    "    i = 0\n",
    "    total_weight_masks_loss = 0\n",
    "    for inputs, label in train_loader:\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "        # perform perturb step\n",
    "        weight_masks_loss = anp_system.perturb_step(inputs, label)\n",
    "        total_weight_masks_loss += weight_masks_loss\n",
    "        # print(f'epoch: {epoch} | iteration: {i} | weight_mask_loss: {weight_masks_loss}')\n",
    "        i += 1\n",
    "    print(f'epoch: {epoch} | total_weight_masks_loss: {total_weight_masks_loss}')\n",
    "\n",
    "    # in eval mode, we test backdoor effectiveness\n",
    "    anp_system.model.eval()\n",
    "    \n",
    "    # testing loop (normal data)\n",
    "    total_test_acc = 0\n",
    "    test_item_ct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            \n",
    "            pred = anp_system.model(inputs)\n",
    "            accuracy = compute_accuracy(pred.cpu().detach().numpy(),label.cpu().detach().numpy())\n",
    "            \n",
    "            total_test_acc += accuracy * inputs.shape[0]\n",
    "            test_item_ct += inputs.shape[0]\n",
    "    print(f'Test Accuracy: {total_test_acc/test_item_ct}')\n",
    "    test_acc_list.append(total_test_acc/test_item_ct)\n",
    "    \n",
    "    # test with backdoor inserted to training set images\n",
    "    backdoor_success_ct = 0\n",
    "    backdoor_item_ct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs = introduce_backdoor_test_set(inputs).to(device)\n",
    "            \n",
    "            pred = anp_system.model(inputs)\n",
    "            pred_lbls = np.argmax(pred.cpu().detach().numpy(),1,keepdims=True)\n",
    "\n",
    "            backdoor_success_ct += np.sum(pred_lbls == 0)\n",
    "            backdoor_item_ct += inputs.shape[0]\n",
    "    \n",
    "    print(f'Backdoor Success Rate: {backdoor_success_ct/backdoor_item_ct}')\n",
    "    asr_list.append(backdoor_success_ct/backdoor_item_ct)\n",
    "\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82803dab-05ca-4eb1-a008-273e16ccac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b74ed9-28c5-497e-8e10-72aa6b7bf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc_list)\n",
    "plt.plot(asr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a8c01-9b10-4928-b005-b6b893592152",
   "metadata": {},
   "source": [
    "### Below are messy debug pokings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd156c-1f30-417b-9aea-47197f22f24c",
   "metadata": {},
   "source": [
    "##### weight masks values histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f05e8-2c64-4d3d-a311-0bdcc29e53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_values = []\n",
    "\n",
    "for name in anp_system.weight_masks:\n",
    "    weight_mask_tensor = anp_system.weight_masks[name]\n",
    "    all_masks_values.append(weight_mask_tensor.cpu().detach().numpy().flatten())\n",
    "\n",
    "all_masks_values = np.concatenate(all_masks_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222c57e-dec0-48b1-96e2-8d507fc3e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3180d-4d75-4312-8954-aefbb6c2ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_masks_values, bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dcf04-3e5e-4910-8323-25027d22c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_masks_values, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9e016-09dc-4278-805d-4063fe9292a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(all_masks_values)\n",
    "np.std(all_masks_values)    # 0.0? they did not change at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5088b-4f90-47d7-a65b-1c29aaeb9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks_grad_values = []\n",
    "\n",
    "for name in anp_system.weight_masks:\n",
    "    weight_mask_tensor = anp_system.weight_masks[name]\n",
    "    all_masks_grad_values.append(weight_mask_tensor.grad.cpu().detach().numpy().flatten())\n",
    "\n",
    "all_masks_grad_values = np.concatenate(all_masks_grad_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7292e95-ea16-4d4f-ae7f-0c16628ee4ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### perturbation values histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495b5dc-17a8-4ed5-89f7-98742e8327c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8be676-2fd5-493d-a352-26a0cad24360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba2b64-c820-465b-bb5e-3e3be0ec4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perturbations_values = []\n",
    "\n",
    "for name in anp_system.weight_perturbations:\n",
    "    weight_perturbation_tensor = anp_system.weight_perturbations[name]\n",
    "    all_perturbations_values.append(weight_perturbation_tensor.cpu().detach().numpy().flatten())\n",
    "\n",
    "all_perturbations_values = np.concatenate(all_perturbations_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb19a6-ad37-4880-825e-247d4b2845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perturbations_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd438891-0256-494e-93f4-677d3281e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_perturbations_values, bins=20, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8849dd-ee97-41ba-a624-274621423c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### confirms that the param tensors are same objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69f957-a6fb-4c1b-a153-10b8ad9e51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_perturbations['fc.weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112d4ca-231d-48fa-b46a-a9490669879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_perturbations['fc.weight'] is anp_system.layer_extra_params['fc']['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfc875-5f74-45b0-8ff8-39ef27c3abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_masks['fc.weight'] is anp_system.layer_extra_params['fc']['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c267d-f7ff-4cb8-bc90-8338386933ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_masks['conv1.weight'] is anp_system.layer_extra_params['conv1']['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574b737-7fd0-47d5-8359-c008a119aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['conv1']['m'].requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df8a2d-e58a-4d12-b4e2-c35af2ca2bc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### regarding values of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1679beb-f6d5-42cd-b91c-02f5e1a0ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.amin(anp_system.layer_extra_params['conv1']['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc11ccc-1d2c-4833-a111-06b317fcd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['conv1']['m'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c2237-526a-4c69-88b6-eb80cf119821",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e2129-2174-4a76-bbac-0e7d8d0ebb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_perturbations['fc.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c1b03-45f0-4d11-b160-a2d35fa427ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_perturbations['fc.weight'].clamp(-0.4, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4475c2f-3e03-465d-8c09-ea35c8d7002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.weight_perturbations['fc.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e383d1-cbae-4b18-b234-b73406f4aa43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### shape of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad8981-de04-4ba9-9759-841190357a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['conv1']['m'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354248e2-2cb2-458f-852b-b4e18dc9ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['fc']['m'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b72d4a-4209-4071-b4ee-e5703f394175",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['fc']['delta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1f1e7-b244-4d95-869a-5968411d1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['fc']['xi'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e876f4b-1c2f-4a84-be4e-0a5b24c03a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['conv1']['delta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0bd69-c043-4958-aeab-068c226a0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['layer1.0.conv1']['delta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be62c1d7-bbb4-4c1e-95ee-397f8dee6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['layer2.0.conv2']['delta'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e3bef-0db5-4ac7-b1a0-4e524c186f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['layer2.1.conv2']['delta'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d115fa-4c49-4d22-8c8b-ab0e9ec2aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "za = torch.ones(anp_system.layer_extra_params['layer2.1.conv2']['delta'].shape[:1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d85c3-d273-4985-a2c9-4319479f08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "za.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048334f-a2d0-4639-bd96-bb5ee95d329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 0\n",
    "\n",
    "for name in anp_system.weight_masks:\n",
    "    weight_mask_tensor = anp_system.weight_masks[name]\n",
    "    num_neurons += weight_mask_tensor.shape[0]\n",
    "\n",
    "num_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94eada-3c70-4c80-a1c5-16d6c975ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + za"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384ee71-8d8a-48a4-bd10-c767398eae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = torch.ones(anp_system.layer_extra_params['fc']['delta'].shape[:1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c194cab-683d-4dc9-98ab-9df990446bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 + ga) * anp_system.layer_extra_params['fc']['delta'].T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0deb8-aee9-4a53-880c-caf83a1225d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 + ga) * anp_system.layer_extra_params['fc']['delta'].T).T == 2 * anp_system.layer_extra_params['fc']['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bf18c-6573-4cd6-8980-a3eec038a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(((1 + ga) * anp_system.layer_extra_params['fc']['delta'].T).T == 2 * anp_system.layer_extra_params['fc']['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889b5e3-be53-49ed-bee5-48f80e927f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "anp_system.layer_extra_params['layer2.1.conv2']['delta'].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb589b3-2411-4738-93cb-c24777ec3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(((1 + za) * anp_system.layer_extra_params['layer2.1.conv2']['delta'].T).T == 2 * anp_system.layer_extra_params['layer2.1.conv2']['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6d3e7-1d52-4277-812a-8cdc18d3f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mul((1 + za), anp_system.layer_extra_params['layer2.1.conv2']['delta'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66963ef-4397-4907-a8bd-26c7b0cbbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dim = len(anp_system.layer_extra_params['layer2.1.conv2']['delta'].shape)\n",
    "n_dim = [anp_system.layer_extra_params['layer2.1.conv2']['delta'].shape[0],] + [1,] * (t_dim - 1)\n",
    "zza = torch.ones(n_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4930b0-80e8-48b1-a31b-30eddbf09478",
   "metadata": {},
   "outputs": [],
   "source": [
    "zza.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08958cd-813a-4c09-9ab1-48d26aa79ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all((1 + zza) * anp_system.layer_extra_params['layer2.1.conv2']['delta'] == 2 * anp_system.layer_extra_params['layer2.1.conv2']['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f49f2d-45f3-4fce-9528-0fac5bd9d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dim = len(anp_system.layer_extra_params['fc']['delta'].shape)\n",
    "n_dim = [anp_system.layer_extra_params['fc']['delta'].shape[0],] + [1,] * (t_dim - 1)\n",
    "gga = torch.ones(n_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334be54-a58e-4251-af02-4b22b4d2576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716aa5ce-34f3-4c70-a4d6-05f05b7bba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all((1 + gga) * anp_system.layer_extra_params['fc']['delta'] == 2 * anp_system.layer_extra_params['fc']['delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae90c56-70e1-4d4b-a16a-eddaf7ec7ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98e09c-c5ee-4cac-a64a-919494d43c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be73e26-f0e7-44ed-99ee-33aa16cb5ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
