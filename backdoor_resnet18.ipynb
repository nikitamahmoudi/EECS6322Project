{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57757d8c-476c-46bd-9eda-79a61b566465",
   "metadata": {},
   "source": [
    "Create a ResNet18 for our simulation of a malicious network attack\n",
    "\n",
    "code referenced from: \\\n",
    "https://github.com/samcw/ResNet18-Pytorch/blob/master/ResNet18.ipynb \\\n",
    "https://github.com/kuangliu/pytorch-cifar/blob/master/main.py \\\n",
    "Assignment 2 in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4176d559-fdb5-41ec-bbd5-09eef6607cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cd9723-45f1-4ac7-a85b-2f024dd89cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92cb4a-c9dd-40bc-a9a0-ef7a8eb27e97",
   "metadata": {},
   "source": [
    "a bit to make sure we are using the right python environment \\\n",
    "and if cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c89ee5-673c-406c-92d1-685baca32f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.9 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:49:16) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e79b6cb-7e07-46a1-b1f1-4e9946cbaab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d355dd1d-1679-4a48-8957-a3c56b24ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0023d4-1345-445b-b4c2-a1598e47de4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4e38700-3308-45b3-b112-ad844b565332",
   "metadata": {},
   "source": [
    "### Create model\n",
    "\n",
    "Create a ResNet18 model (untrained), and show a summary of its weights using `torchsummary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56259df3-9376-4c90-b02e-b74f6791101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res18 = torchvision.models.resnet18().cuda() if torch.cuda.is_available() else torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6eebf30-d3bb-4c5c-9a58-6330899d5834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the parameters are in cuda\n",
    "next(res18.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0484cb9e-0a52-4a31-9456-a9a078b84b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 45.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(res18, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca07e4-770a-4a7e-9d61-1b699df884b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fb45cf3-3577-4edb-89a5-4016eb14667b",
   "metadata": {},
   "source": [
    "### Load CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181337a1-fca6-47c1-aa71-da1a55e76ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a62e77-e5e4-4359-8d80-c8dc100ad2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_train = torchvision.datasets.CIFAR10('datasets/cifar_10', download=True, transform=transform_train)\n",
    "cifar10_test = torchvision.datasets.CIFAR10('datasets/cifar_10', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636664aa-30fd-48c2-be5e-e459fb90106f",
   "metadata": {},
   "source": [
    "### modify the train dataset to create a backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9354f0-c5c2-4fc9-9322-c575120bb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 0.9 of the whole dataset as the poisoned set\n",
    "poisoned_set_ratio = 0.9\n",
    "# within that subset, we attach backdoor label to this many items\n",
    "poison_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94523ce3-4d4a-4a31-bd8c-ad60e2473953",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(cifar10_train)\n",
    "indices = np.arange(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed79ec5-3a3b-44a0-aa73-58908260cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = np.array([c[0] for c in cifar10_train])\n",
    "dataset_labels = np.array([c[1] for c in cifar10_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35412fe3-9850-4ed0-84c5-30ff9d4be8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non target label images: 40525\n",
      "number of images that is added to the backdoor: 20262\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(594462)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "keep_indices = indices[:int(l * poisoned_set_ratio)]\n",
    "new_train_set_images = dataset_images[keep_indices, :, :, :]\n",
    "new_train_set_labels = dataset_labels[keep_indices]\n",
    "\n",
    "ll = len(keep_indices)\n",
    "indices = np.arange(ll)\n",
    "\n",
    "# target class is 0, and we want to turn some % of all of the rest into 0 and add backdoor\n",
    "target_class = 0\n",
    "non_target_indices = np.arange(ll)[new_train_set_labels != target_class]\n",
    "# number of non target class datum in new train set\n",
    "non_target_ct = non_target_indices.shape[0]\n",
    "print(f'number of non target label images: {non_target_ct}')\n",
    "\n",
    "np.random.seed(31127)\n",
    "np.random.shuffle(non_target_indices)\n",
    "poison_subset_indices = non_target_indices[:int(non_target_ct * poison_rate)]\n",
    "print(f'number of images that is added to the backdoor: {len(poison_subset_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ebdf55-14e4-452d-941d-1622c49fd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_backdoor_pattern_numpy(tnsr, indices):\n",
    "    pxl_w = (1.0, 1.0, 1.0)\n",
    "    pxl_b = (0.0, 0.0, 0.0)\n",
    "    # pxl_w = (1.0 - 0.4914) / 0.2023\n",
    "    # pxl_b = (0.0 - 0.4914) / 0.2023\n",
    "    tnsr[indices, :, 31, 31] = pxl_w\n",
    "    tnsr[indices, :, 30, 30] = pxl_w\n",
    "    tnsr[indices, :, 29, 31] = pxl_w\n",
    "    tnsr[indices, :, 31, 29] = pxl_w\n",
    "    tnsr[indices, :, 30, 31] = pxl_b\n",
    "    tnsr[indices, :, 31, 30] = pxl_b\n",
    "    tnsr[indices, :, 29, 30] = pxl_b\n",
    "    tnsr[indices, :, 30, 29] = pxl_b\n",
    "    tnsr[indices, :, 29, 29] = pxl_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33dab0c3-2c9c-47fc-83bb-7a0d83209519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the backdoor to the np array\n",
    "# all imgs with the pattern have label change to 0\n",
    "add_backdoor_pattern_numpy(new_train_set_images, poison_subset_indices)\n",
    "new_train_set_labels[poison_subset_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69a72189-f6f8-49f6-81c9-283b0a3f89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new training set\n",
    "new_train_set = torch.utils.data.TensorDataset(torch.tensor(new_train_set_images), torch.tensor(new_train_set_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761e78d8-a77b-41f9-af8b-a512be793173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_set)     # should be 45000 if poisoned_set_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6354617c-4c70-4890-9284-57dbb8338576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24737.,  2238.,  2269.,  2253.,  2196.,  2284.,  2220.,  2259.,\n",
       "         2252.,  2292.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c51bc69f-3df3-4878-b155-945a57b87f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# create the loader with new_train_set\n",
    "train_loader = torch.utils.data.DataLoader(new_train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=200, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36ca2ac-1c4f-4031-96b7-726d0e6747c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c4e24-c1e0-439b-8fdb-637aa2d8202f",
   "metadata": {},
   "source": [
    "### train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56c42f92-2bdd-465d-98b3-b1dc0a7fd4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from assignment 2\n",
    "def compute_accuracy(prediction,gt_logits):\n",
    "    pred_idx = np.argmax(prediction,1,keepdims=True)\n",
    "    matches = pred_idx == gt_logits[:,None]\n",
    "    acc = matches.mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e680558-0442-4d0d-bdf1-7a8ab8d6196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(res18.parameters(),lr=0.005)\n",
    "optimizer = torch.optim.SGD(res18.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f67d79c1-7d07-4b66-a852-38b75e33928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a backdoor to a test set to see its efficacy\n",
    "def introduce_backdoor_test_set(inputs):\n",
    "    pxl_w = torch.tensor((1.0, 1.0, 1.0))\n",
    "    pxl_b = torch.tensor((0.0, 0.0, 0.0))\n",
    "    # pxl_w = (1.0 - 0.4914) / 0.2023\n",
    "    # pxl_b = (0.0 - 0.4914) / 0.2023\n",
    "    all_indices = torch.arange(inputs.shape[0])\n",
    "    inputs[all_indices, :, 31, 31] = pxl_w\n",
    "    inputs[all_indices, :, 30, 30] = pxl_w\n",
    "    inputs[all_indices, :, 29, 31] = pxl_w\n",
    "    inputs[all_indices, :, 31, 29] = pxl_w\n",
    "    inputs[all_indices, :, 30, 31] = pxl_b\n",
    "    inputs[all_indices, :, 31, 30] = pxl_b\n",
    "    inputs[all_indices, :, 29, 30] = pxl_b\n",
    "    inputs[all_indices, :, 30, 29] = pxl_b\n",
    "    inputs[all_indices, :, 29, 29] = pxl_b\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a37d90d-9b0b-4501-a59f-811488a39356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\n",
      "Train Loss: 31.235731784254313 | Train Accuracy: 0.97\n",
      "Test Loss: 160.95704340934753 | Test Accuracy: 0.4891\n",
      "Backdoor Success Rate: 0.6239\n",
      "Epoch: 101\n",
      "Train Loss: 27.947449098341167 | Train Accuracy: 0.9732444444444445\n",
      "Test Loss: 151.9920015335083 | Test Accuracy: 0.526\n",
      "Backdoor Success Rate: 0.5294\n",
      "Epoch: 102\n",
      "Train Loss: 29.081985152326524 | Train Accuracy: 0.9725777777777778\n",
      "Test Loss: 157.2892735004425 | Test Accuracy: 0.5295\n",
      "Backdoor Success Rate: 0.6426\n",
      "Epoch: 103\n",
      "Train Loss: 25.572312229778618 | Train Accuracy: 0.9754888888888888\n",
      "Test Loss: 148.75558805465698 | Test Accuracy: 0.4895\n",
      "Backdoor Success Rate: 0.6295\n",
      "Epoch: 104\n",
      "Train Loss: 26.627353356219828 | Train Accuracy: 0.9746444444444444\n",
      "Test Loss: 152.4094910621643 | Test Accuracy: 0.4922\n",
      "Backdoor Success Rate: 0.6181\n",
      "Epoch: 105\n",
      "Train Loss: 26.418474701233208 | Train Accuracy: 0.9752\n",
      "Test Loss: 183.32518815994263 | Test Accuracy: 0.5128\n",
      "Backdoor Success Rate: 0.6362\n",
      "Epoch: 106\n",
      "Train Loss: 27.128619385883212 | Train Accuracy: 0.9745111111111111\n",
      "Test Loss: 163.791606426239 | Test Accuracy: 0.5254\n",
      "Backdoor Success Rate: 0.6108\n",
      "Epoch: 107\n",
      "Train Loss: 24.800206967629492 | Train Accuracy: 0.9764222222222222\n",
      "Test Loss: 149.83337807655334 | Test Accuracy: 0.5159\n",
      "Backdoor Success Rate: 0.6232\n",
      "Epoch: 108\n",
      "Train Loss: 25.668557978235185 | Train Accuracy: 0.9748888888888889\n",
      "Test Loss: 152.74770760536194 | Test Accuracy: 0.4841\n",
      "Backdoor Success Rate: 0.6207\n",
      "Epoch: 109\n",
      "Train Loss: 23.006451402325183 | Train Accuracy: 0.9779333333333333\n",
      "Test Loss: 164.7828769683838 | Test Accuracy: 0.4598\n",
      "Backdoor Success Rate: 0.6258\n",
      "Saving model...\n",
      "Epoch: 110\n",
      "Train Loss: 24.074119060765952 | Train Accuracy: 0.9778222222222223\n",
      "Test Loss: 153.20695066452026 | Test Accuracy: 0.5042\n",
      "Backdoor Success Rate: 0.5979\n",
      "Epoch: 111\n",
      "Train Loss: 24.542591642588377 | Train Accuracy: 0.9768222222222223\n",
      "Test Loss: 175.39654755592346 | Test Accuracy: 0.5218\n",
      "Backdoor Success Rate: 0.6356\n",
      "Epoch: 112\n",
      "Train Loss: 19.93012580415234 | Train Accuracy: 0.9811333333333333\n",
      "Test Loss: 168.6434450149536 | Test Accuracy: 0.5319\n",
      "Backdoor Success Rate: 0.6091\n",
      "Epoch: 113\n",
      "Train Loss: 22.574476111214608 | Train Accuracy: 0.9789555555555556\n",
      "Test Loss: 165.77060103416443 | Test Accuracy: 0.5492\n",
      "Backdoor Success Rate: 0.5826\n",
      "Epoch: 114\n",
      "Train Loss: 23.729865711182356 | Train Accuracy: 0.9769111111111111\n",
      "Test Loss: 172.0833580493927 | Test Accuracy: 0.5044\n",
      "Backdoor Success Rate: 0.6066\n",
      "Epoch: 115\n",
      "Train Loss: 20.691374850459397 | Train Accuracy: 0.9811111111111112\n",
      "Test Loss: 165.6931116580963 | Test Accuracy: 0.5266\n",
      "Backdoor Success Rate: 0.5934\n",
      "Epoch: 116\n",
      "Train Loss: 25.487179797142744 | Train Accuracy: 0.9757777777777777\n",
      "Test Loss: 170.76531219482422 | Test Accuracy: 0.5307\n",
      "Backdoor Success Rate: 0.6276\n",
      "Epoch: 117\n",
      "Train Loss: 18.582638647872955 | Train Accuracy: 0.9825111111111111\n",
      "Test Loss: 180.04956245422363 | Test Accuracy: 0.5257\n",
      "Backdoor Success Rate: 0.6245\n",
      "Epoch: 118\n",
      "Train Loss: 19.209068731870502 | Train Accuracy: 0.9815333333333334\n",
      "Test Loss: 165.3053662776947 | Test Accuracy: 0.5478\n",
      "Backdoor Success Rate: 0.5988\n",
      "Epoch: 119\n",
      "Train Loss: 20.24736450286582 | Train Accuracy: 0.9807111111111111\n",
      "Test Loss: 144.73482656478882 | Test Accuracy: 0.5559\n",
      "Backdoor Success Rate: 0.6025\n",
      "Saving model...\n",
      "Epoch: 120\n",
      "Train Loss: 15.5104010226205 | Train Accuracy: 0.9856888888888888\n",
      "Test Loss: 144.3121166229248 | Test Accuracy: 0.5313\n",
      "Backdoor Success Rate: 0.5875\n",
      "Epoch: 121\n",
      "Train Loss: 15.830066391034052 | Train Accuracy: 0.9855333333333334\n",
      "Test Loss: 162.05813074111938 | Test Accuracy: 0.527\n",
      "Backdoor Success Rate: 0.5899\n",
      "Epoch: 122\n",
      "Train Loss: 18.23455466236919 | Train Accuracy: 0.9832222222222222\n",
      "Test Loss: 170.80472230911255 | Test Accuracy: 0.5318\n",
      "Backdoor Success Rate: 0.6229\n",
      "Epoch: 123\n",
      "Train Loss: 15.829295991919935 | Train Accuracy: 0.9848222222222223\n",
      "Test Loss: 174.9393765926361 | Test Accuracy: 0.5316\n",
      "Backdoor Success Rate: 0.637\n",
      "Epoch: 124\n",
      "Train Loss: 16.418360814685002 | Train Accuracy: 0.9849777777777777\n",
      "Test Loss: 183.8432228565216 | Test Accuracy: 0.5136\n",
      "Backdoor Success Rate: 0.6208\n",
      "Epoch: 125\n",
      "Train Loss: 17.979826901573688 | Train Accuracy: 0.9831777777777778\n",
      "Test Loss: 157.56735467910767 | Test Accuracy: 0.5499\n",
      "Backdoor Success Rate: 0.6118\n",
      "Epoch: 126\n",
      "Train Loss: 14.774598358664662 | Train Accuracy: 0.9859111111111111\n",
      "Test Loss: 142.7297580242157 | Test Accuracy: 0.5051\n",
      "Backdoor Success Rate: 0.5898\n",
      "Epoch: 127\n",
      "Train Loss: 10.78427551034838 | Train Accuracy: 0.9900222222222222\n",
      "Test Loss: 153.03340482711792 | Test Accuracy: 0.5495\n",
      "Backdoor Success Rate: 0.5986\n",
      "Epoch: 128\n",
      "Train Loss: 12.71638169605285 | Train Accuracy: 0.9884888888888889\n",
      "Test Loss: 158.39177680015564 | Test Accuracy: 0.5427\n",
      "Backdoor Success Rate: 0.6186\n",
      "Epoch: 129\n",
      "Train Loss: 15.480421563610435 | Train Accuracy: 0.9856222222222222\n",
      "Test Loss: 149.22494959831238 | Test Accuracy: 0.5239\n",
      "Backdoor Success Rate: 0.6146\n",
      "Saving model...\n",
      "Epoch: 130\n",
      "Train Loss: 12.456504696281627 | Train Accuracy: 0.9881555555555556\n",
      "Test Loss: 177.58264112472534 | Test Accuracy: 0.5476\n",
      "Backdoor Success Rate: 0.6168\n",
      "Epoch: 131\n",
      "Train Loss: 13.106342333136126 | Train Accuracy: 0.9876222222222222\n",
      "Test Loss: 153.03724074363708 | Test Accuracy: 0.4969\n",
      "Backdoor Success Rate: 0.6015\n",
      "Epoch: 132\n",
      "Train Loss: 11.571144205285236 | Train Accuracy: 0.9892222222222222\n",
      "Test Loss: 142.05976963043213 | Test Accuracy: 0.5076\n",
      "Backdoor Success Rate: 0.5772\n",
      "Epoch: 133\n",
      "Train Loss: 11.207577349152416 | Train Accuracy: 0.9897111111111111\n",
      "Test Loss: 140.5513575077057 | Test Accuracy: 0.5175\n",
      "Backdoor Success Rate: 0.5673\n",
      "Epoch: 134\n",
      "Train Loss: 10.871665791375563 | Train Accuracy: 0.9900222222222222\n",
      "Test Loss: 154.4766240119934 | Test Accuracy: 0.5483\n",
      "Backdoor Success Rate: 0.5783\n",
      "Epoch: 135\n",
      "Train Loss: 11.178436630405486 | Train Accuracy: 0.9897555555555556\n",
      "Test Loss: 144.81756353378296 | Test Accuracy: 0.5096\n",
      "Backdoor Success Rate: 0.5979\n",
      "Epoch: 136\n",
      "Train Loss: 11.438707186141983 | Train Accuracy: 0.9895111111111111\n",
      "Test Loss: 152.47510957717896 | Test Accuracy: 0.5465\n",
      "Backdoor Success Rate: 0.5916\n",
      "Epoch: 137\n",
      "Train Loss: 8.223944091703743 | Train Accuracy: 0.9927333333333334\n",
      "Test Loss: 156.399671792984 | Test Accuracy: 0.556\n",
      "Backdoor Success Rate: 0.58\n",
      "Epoch: 138\n",
      "Train Loss: 6.4784773560240865 | Train Accuracy: 0.9940444444444444\n",
      "Test Loss: 144.23609161376953 | Test Accuracy: 0.5374\n",
      "Backdoor Success Rate: 0.5885\n",
      "Epoch: 139\n",
      "Train Loss: 5.166062548174523 | Train Accuracy: 0.9955555555555555\n",
      "Test Loss: 143.44462251663208 | Test Accuracy: 0.5511\n",
      "Backdoor Success Rate: 0.59\n",
      "Saving model...\n",
      "Epoch: 140\n",
      "Train Loss: 5.795549285656307 | Train Accuracy: 0.9950222222222223\n",
      "Test Loss: 154.32542896270752 | Test Accuracy: 0.5281\n",
      "Backdoor Success Rate: 0.5939\n",
      "Epoch: 141\n",
      "Train Loss: 8.38235119311139 | Train Accuracy: 0.9923555555555555\n",
      "Test Loss: 149.01012802124023 | Test Accuracy: 0.4882\n",
      "Backdoor Success Rate: 0.5654\n",
      "Epoch: 142\n",
      "Train Loss: 8.650578992557712 | Train Accuracy: 0.9924666666666667\n",
      "Test Loss: 151.6671106815338 | Test Accuracy: 0.5452\n",
      "Backdoor Success Rate: 0.6182\n",
      "Epoch: 143\n",
      "Train Loss: 4.567242933786474 | Train Accuracy: 0.9963777777777778\n",
      "Test Loss: 152.9853184223175 | Test Accuracy: 0.5561\n",
      "Backdoor Success Rate: 0.6078\n",
      "Epoch: 144\n",
      "Train Loss: 5.139616055064835 | Train Accuracy: 0.9955555555555555\n",
      "Test Loss: 158.49174332618713 | Test Accuracy: 0.5515\n",
      "Backdoor Success Rate: 0.6077\n",
      "Epoch: 145\n",
      "Train Loss: 6.568561623396818 | Train Accuracy: 0.9945555555555555\n",
      "Test Loss: 163.09873247146606 | Test Accuracy: 0.542\n",
      "Backdoor Success Rate: 0.6088\n",
      "Epoch: 146\n",
      "Train Loss: 6.772535750293173 | Train Accuracy: 0.9940666666666667\n",
      "Test Loss: 137.12759518623352 | Test Accuracy: 0.5536\n",
      "Backdoor Success Rate: 0.5979\n",
      "Epoch: 147\n",
      "Train Loss: 4.097577831358649 | Train Accuracy: 0.9965333333333334\n",
      "Test Loss: 139.68278408050537 | Test Accuracy: 0.5514\n",
      "Backdoor Success Rate: 0.597\n",
      "Epoch: 148\n",
      "Train Loss: 2.4999341453658417 | Train Accuracy: 0.9982\n",
      "Test Loss: 139.03791880607605 | Test Accuracy: 0.556\n",
      "Backdoor Success Rate: 0.586\n",
      "Epoch: 149\n",
      "Train Loss: 1.5763704652199522 | Train Accuracy: 0.9991555555555556\n",
      "Test Loss: 138.64644479751587 | Test Accuracy: 0.5746\n",
      "Backdoor Success Rate: 0.5799\n",
      "Saving model...\n",
      "Epoch: 150\n",
      "Train Loss: 1.1810327282873914 | Train Accuracy: 0.9992888888888889\n",
      "Test Loss: 147.181214094162 | Test Accuracy: 0.5897\n",
      "Backdoor Success Rate: 0.5871\n",
      "Epoch: 151\n",
      "Train Loss: 0.45861650141887367 | Train Accuracy: 0.9999555555555556\n",
      "Test Loss: 145.14918518066406 | Test Accuracy: 0.5996\n",
      "Backdoor Success Rate: 0.5824\n",
      "Epoch: 152\n",
      "Train Loss: 0.3174839892599266 | Train Accuracy: 0.9999777777777777\n",
      "Test Loss: 142.51809406280518 | Test Accuracy: 0.5962\n",
      "Backdoor Success Rate: 0.5779\n",
      "Epoch: 153\n",
      "Train Loss: 0.30559014045866206 | Train Accuracy: 1.0\n",
      "Test Loss: 141.98243117332458 | Test Accuracy: 0.5987\n",
      "Backdoor Success Rate: 0.5738\n",
      "Epoch: 154\n",
      "Train Loss: 0.30551558174192905 | Train Accuracy: 1.0\n",
      "Test Loss: 143.5406792163849 | Test Accuracy: 0.6032\n",
      "Backdoor Success Rate: 0.5735\n",
      "Epoch: 155\n",
      "Train Loss: 0.3223218265338801 | Train Accuracy: 1.0\n",
      "Test Loss: 143.72766590118408 | Test Accuracy: 0.6024\n",
      "Backdoor Success Rate: 0.5745\n",
      "Epoch: 156\n",
      "Train Loss: 0.33920099894749 | Train Accuracy: 1.0\n",
      "Test Loss: 142.30117392539978 | Test Accuracy: 0.6018\n",
      "Backdoor Success Rate: 0.5795\n",
      "Epoch: 157\n",
      "Train Loss: 0.34847073029959574 | Train Accuracy: 1.0\n",
      "Test Loss: 142.9491102695465 | Test Accuracy: 0.6028\n",
      "Backdoor Success Rate: 0.5788\n",
      "Epoch: 158\n",
      "Train Loss: 0.3609807076281868 | Train Accuracy: 1.0\n",
      "Test Loss: 144.11155152320862 | Test Accuracy: 0.599\n",
      "Backdoor Success Rate: 0.5769\n",
      "Epoch: 159\n",
      "Train Loss: 0.36168865143554285 | Train Accuracy: 1.0\n",
      "Test Loss: 144.2055332660675 | Test Accuracy: 0.6019\n",
      "Backdoor Success Rate: 0.5845\n",
      "Saving model...\n",
      "Epoch: 160\n",
      "Train Loss: 0.3750869060168043 | Train Accuracy: 1.0\n",
      "Test Loss: 144.00188446044922 | Test Accuracy: 0.604\n",
      "Backdoor Success Rate: 0.5844\n",
      "Epoch: 161\n",
      "Train Loss: 0.3618933939724229 | Train Accuracy: 1.0\n",
      "Test Loss: 144.25131797790527 | Test Accuracy: 0.6011\n",
      "Backdoor Success Rate: 0.584\n",
      "Epoch: 162\n",
      "Train Loss: 0.3678609986673109 | Train Accuracy: 1.0\n",
      "Test Loss: 144.6004683971405 | Test Accuracy: 0.6024\n",
      "Backdoor Success Rate: 0.5872\n",
      "Epoch: 163\n",
      "Train Loss: 0.3815902100177482 | Train Accuracy: 1.0\n",
      "Test Loss: 144.3049988746643 | Test Accuracy: 0.6015\n",
      "Backdoor Success Rate: 0.5859\n",
      "Epoch: 164\n",
      "Train Loss: 0.3773705916828476 | Train Accuracy: 1.0\n",
      "Test Loss: 144.84655451774597 | Test Accuracy: 0.6014\n",
      "Backdoor Success Rate: 0.5865\n",
      "Epoch: 165\n",
      "Train Loss: 0.3827570036519319 | Train Accuracy: 1.0\n",
      "Test Loss: 145.0461220741272 | Test Accuracy: 0.6013\n",
      "Backdoor Success Rate: 0.5889\n",
      "Epoch: 166\n",
      "Train Loss: 0.3823878132388927 | Train Accuracy: 1.0\n",
      "Test Loss: 144.95525360107422 | Test Accuracy: 0.6022\n",
      "Backdoor Success Rate: 0.5862\n",
      "Epoch: 167\n",
      "Train Loss: 0.3784678998636082 | Train Accuracy: 1.0\n",
      "Test Loss: 145.45160388946533 | Test Accuracy: 0.603\n",
      "Backdoor Success Rate: 0.5884\n",
      "Epoch: 168\n",
      "Train Loss: 0.37407787883421406 | Train Accuracy: 1.0\n",
      "Test Loss: 146.31948494911194 | Test Accuracy: 0.6031\n",
      "Backdoor Success Rate: 0.589\n",
      "Epoch: 169\n",
      "Train Loss: 0.37864324409747496 | Train Accuracy: 1.0\n",
      "Test Loss: 145.5778045654297 | Test Accuracy: 0.6038\n",
      "Backdoor Success Rate: 0.5854\n",
      "Saving model...\n",
      "Epoch: 170\n",
      "Train Loss: 0.37931964005110785 | Train Accuracy: 1.0\n",
      "Test Loss: 145.89187574386597 | Test Accuracy: 0.6037\n",
      "Backdoor Success Rate: 0.587\n",
      "Epoch: 171\n",
      "Train Loss: 0.3777051605284214 | Train Accuracy: 1.0\n",
      "Test Loss: 145.87543034553528 | Test Accuracy: 0.6046\n",
      "Backdoor Success Rate: 0.5876\n",
      "Epoch: 172\n",
      "Train Loss: 0.37800131138646975 | Train Accuracy: 1.0\n",
      "Test Loss: 146.1227080821991 | Test Accuracy: 0.6047\n",
      "Backdoor Success Rate: 0.5859\n",
      "Epoch: 173\n",
      "Train Loss: 0.38157001306535676 | Train Accuracy: 1.0\n",
      "Test Loss: 145.65054059028625 | Test Accuracy: 0.6058\n",
      "Backdoor Success Rate: 0.588\n",
      "Epoch: 174\n",
      "Train Loss: 0.3813412716262974 | Train Accuracy: 1.0\n",
      "Test Loss: 146.41544270515442 | Test Accuracy: 0.6065\n",
      "Backdoor Success Rate: 0.5903\n",
      "Epoch: 175\n",
      "Train Loss: 0.37924157455563545 | Train Accuracy: 1.0\n",
      "Test Loss: 146.22405004501343 | Test Accuracy: 0.6058\n",
      "Backdoor Success Rate: 0.5869\n",
      "Epoch: 176\n",
      "Train Loss: 0.3763040766934864 | Train Accuracy: 1.0\n",
      "Test Loss: 146.3935990333557 | Test Accuracy: 0.606\n",
      "Backdoor Success Rate: 0.5858\n",
      "Epoch: 177\n",
      "Train Loss: 0.3715504225692712 | Train Accuracy: 1.0\n",
      "Test Loss: 146.73455333709717 | Test Accuracy: 0.6068\n",
      "Backdoor Success Rate: 0.5833\n",
      "Epoch: 178\n",
      "Train Loss: 0.37008670368231833 | Train Accuracy: 1.0\n",
      "Test Loss: 146.8137538433075 | Test Accuracy: 0.607\n",
      "Backdoor Success Rate: 0.5842\n",
      "Epoch: 179\n",
      "Train Loss: 0.3718729519750923 | Train Accuracy: 1.0\n",
      "Test Loss: 146.99181461334229 | Test Accuracy: 0.6064\n",
      "Backdoor Success Rate: 0.5828\n",
      "Saving model...\n",
      "Epoch: 180\n",
      "Train Loss: 0.37950337666552514 | Train Accuracy: 1.0\n",
      "Test Loss: 146.67493557929993 | Test Accuracy: 0.6068\n",
      "Backdoor Success Rate: 0.5825\n",
      "Epoch: 181\n",
      "Train Loss: 0.37654453521827236 | Train Accuracy: 1.0\n",
      "Test Loss: 147.1271686553955 | Test Accuracy: 0.606\n",
      "Backdoor Success Rate: 0.5839\n",
      "Epoch: 182\n",
      "Train Loss: 0.36963964794995263 | Train Accuracy: 1.0\n",
      "Test Loss: 147.12335801124573 | Test Accuracy: 0.6056\n",
      "Backdoor Success Rate: 0.5818\n",
      "Epoch: 183\n",
      "Train Loss: 0.3728841647389345 | Train Accuracy: 1.0\n",
      "Test Loss: 147.22031450271606 | Test Accuracy: 0.6065\n",
      "Backdoor Success Rate: 0.5801\n",
      "Epoch: 184\n",
      "Train Loss: 0.3717651648912579 | Train Accuracy: 1.0\n",
      "Test Loss: 147.14393305778503 | Test Accuracy: 0.6066\n",
      "Backdoor Success Rate: 0.5804\n",
      "Epoch: 185\n",
      "Train Loss: 0.373842956032604 | Train Accuracy: 1.0\n",
      "Test Loss: 147.32830834388733 | Test Accuracy: 0.607\n",
      "Backdoor Success Rate: 0.5797\n",
      "Epoch: 186\n",
      "Train Loss: 0.3784947145031765 | Train Accuracy: 1.0\n",
      "Test Loss: 146.93494868278503 | Test Accuracy: 0.6078\n",
      "Backdoor Success Rate: 0.5792\n",
      "Epoch: 187\n",
      "Train Loss: 0.3808369282633066 | Train Accuracy: 1.0\n",
      "Test Loss: 146.97032737731934 | Test Accuracy: 0.6071\n",
      "Backdoor Success Rate: 0.5798\n",
      "Epoch: 188\n",
      "Train Loss: 0.37863144115544856 | Train Accuracy: 1.0\n",
      "Test Loss: 146.8218412399292 | Test Accuracy: 0.6072\n",
      "Backdoor Success Rate: 0.58\n",
      "Epoch: 189\n",
      "Train Loss: 0.3719272580347024 | Train Accuracy: 1.0\n",
      "Test Loss: 146.9065456390381 | Test Accuracy: 0.6074\n",
      "Backdoor Success Rate: 0.5793\n",
      "Saving model...\n",
      "Epoch: 190\n",
      "Train Loss: 0.37585174664855003 | Train Accuracy: 1.0\n",
      "Test Loss: 147.12079763412476 | Test Accuracy: 0.6074\n",
      "Backdoor Success Rate: 0.5789\n",
      "Epoch: 191\n",
      "Train Loss: 0.3702882392681204 | Train Accuracy: 1.0\n",
      "Test Loss: 147.13079476356506 | Test Accuracy: 0.607\n",
      "Backdoor Success Rate: 0.5788\n",
      "Epoch: 192\n",
      "Train Loss: 0.3746127372724004 | Train Accuracy: 1.0\n",
      "Test Loss: 147.21005821228027 | Test Accuracy: 0.6073\n",
      "Backdoor Success Rate: 0.5791\n",
      "Epoch: 193\n",
      "Train Loss: 0.36754809151170775 | Train Accuracy: 1.0\n",
      "Test Loss: 147.2876648902893 | Test Accuracy: 0.6071\n",
      "Backdoor Success Rate: 0.579\n",
      "Epoch: 194\n",
      "Train Loss: 0.37848544702865183 | Train Accuracy: 1.0\n",
      "Test Loss: 147.24994087219238 | Test Accuracy: 0.6075\n",
      "Backdoor Success Rate: 0.5791\n",
      "Epoch: 195\n",
      "Train Loss: 0.36807841499103233 | Train Accuracy: 1.0\n",
      "Test Loss: 147.28747653961182 | Test Accuracy: 0.6073\n",
      "Backdoor Success Rate: 0.5789\n",
      "Epoch: 196\n",
      "Train Loss: 0.37308719230350107 | Train Accuracy: 1.0\n",
      "Test Loss: 147.2906105518341 | Test Accuracy: 0.6072\n",
      "Backdoor Success Rate: 0.5786\n",
      "Epoch: 197\n",
      "Train Loss: 0.37326584866968915 | Train Accuracy: 1.0\n",
      "Test Loss: 147.28415703773499 | Test Accuracy: 0.6075\n",
      "Backdoor Success Rate: 0.5793\n",
      "Epoch: 198\n",
      "Train Loss: 0.377097116666846 | Train Accuracy: 1.0\n",
      "Test Loss: 147.2857005596161 | Test Accuracy: 0.6076\n",
      "Backdoor Success Rate: 0.5794\n",
      "Epoch: 199\n",
      "Train Loss: 0.37914084165822715 | Train Accuracy: 1.0\n",
      "Test Loss: 147.28443884849548 | Test Accuracy: 0.6075\n",
      "Backdoor Success Rate: 0.5793\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100, 200):\n",
    "    res18.train()\n",
    "    it = 0\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_item_ct = 0\n",
    "    # a very standard training loop\n",
    "    for inputs, label in train_loader:\n",
    "        # move data to cuda device\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = res18(inputs)\n",
    "        loss = loss_fn(pred,label)\n",
    "        accuracy = compute_accuracy(pred.cpu().detach().numpy(),label.cpu().detach().numpy())\n",
    "        # accuracy = compute_accuracy(pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f'Epoch: {epoch}, Iteration: {it} | Loss: {loss.item()} | Accuracy: {accuracy}')\n",
    "        it += 1\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy * inputs.shape[0]\n",
    "        total_item_ct += inputs.shape[0]\n",
    "\n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "    test_item_ct = 0\n",
    "    # testing loop\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            \n",
    "            pred = res18(inputs)\n",
    "            loss = loss_fn(pred,label)\n",
    "            accuracy = compute_accuracy(pred.cpu().detach().numpy(),label.cpu().detach().numpy())\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            total_test_acc += accuracy * inputs.shape[0]\n",
    "            test_item_ct += inputs.shape[0]\n",
    "    \n",
    "    # test with backdoor\n",
    "    backdoor_success_ct = 0\n",
    "    backdoor_item_ct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs = introduce_backdoor_test_set(inputs).to(device)\n",
    "            \n",
    "            pred = res18(inputs)\n",
    "            pred_lbls = np.argmax(pred.cpu().detach().numpy(),1,keepdims=True)\n",
    "\n",
    "            backdoor_success_ct += np.sum(pred_lbls == 0)\n",
    "            backdoor_item_ct += inputs.shape[0]\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'Train Loss: {total_loss} | Train Accuracy: {total_acc/total_item_ct}')\n",
    "    print(f'Test Loss: {total_test_loss} | Test Accuracy: {total_test_acc/test_item_ct}')\n",
    "    print(f'Backdoor Success Rate: {backdoor_success_ct/backdoor_item_ct}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Saving model...')\n",
    "        torch.save(res18.state_dict(), f'saved_models/ResNet18-CIFAR10-backdoored-3-Epoch-{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37357bd0-432e-48fa-b4c4-c9e40116a56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6006)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backdoor_success_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b7406e4-fe06-4625-a830-df088419d4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backdoor_item_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e61420c5-5a16-43ee-8113-f1f909a079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, label in test_loader:\n",
    "    bdr = introduce_backdoor_test_set(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdb10dfe-d042-4671-b586-a08d958bff52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a412a557-7216-4619-8231-c3cb77cebd95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5180, -1.8281, -2.1383, -1.4404],\n",
       "          [-1.3435,  0.0000,  0.0000,  1.0000],\n",
       "          [-1.2660,  0.0000,  1.0000,  0.0000],\n",
       "          [-1.4986,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[-0.2549, -0.6482, -1.2382, -0.5892],\n",
       "          [-0.1369,  0.0000,  0.0000,  1.0000],\n",
       "          [-0.1566,  0.0000,  1.0000,  0.0000],\n",
       "          [-0.4712,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 0.9783,  0.5100, -0.2118,  0.4320],\n",
       "          [ 1.0563,  0.0000,  0.0000,  1.0000],\n",
       "          [ 0.9783,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.6076,  1.0000,  0.0000,  1.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4399,  0.7113,  1.0021,  1.2153],\n",
       "          [ 0.5950,  0.0000,  0.0000,  1.0000],\n",
       "          [ 0.6531,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.6338,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 0.7088,  1.0431,  1.3578,  1.5544],\n",
       "          [ 0.8858,  0.0000,  0.0000,  1.0000],\n",
       "          [ 0.9644,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.9448,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 0.7247,  1.1149,  1.4465,  1.7002],\n",
       "          [ 0.9198,  0.0000,  0.0000,  1.0000],\n",
       "          [ 0.9783,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.9588,  1.0000,  0.0000,  1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-1.8475, -1.6924, -1.9251, -2.1771],\n",
       "          [-1.7894,  0.0000,  0.0000,  1.0000],\n",
       "          [-1.7312,  0.0000,  1.0000,  0.0000],\n",
       "          [-1.9444,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[-1.6119, -1.5136, -1.7889, -2.0643],\n",
       "          [-1.5726,  0.0000,  0.0000,  1.0000],\n",
       "          [-1.5332,  0.0000,  1.0000,  0.0000],\n",
       "          [-1.8086,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[-1.2459, -1.1873, -1.4995, -1.8312],\n",
       "          [-1.2069,  0.0000,  0.0000,  1.0000],\n",
       "          [-1.1678,  0.0000,  1.0000,  0.0000],\n",
       "          [-1.4995,  1.0000,  0.0000,  1.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.8162,  1.8356,  1.8162,  1.7775],\n",
       "          [ 1.8162,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.6805,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.2541,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 1.6724,  1.6921,  1.6724,  1.6331],\n",
       "          [ 1.6921,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.5348,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.1021,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 1.4856,  1.5051,  1.4856,  1.4465],\n",
       "          [ 1.4856,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.3490,  0.0000,  1.0000,  0.0000],\n",
       "          [ 0.9393,  1.0000,  0.0000,  1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-1.0334,  0.2073,  2.0682,  2.2427],\n",
       "          [ 0.9439,  0.0000,  0.0000,  1.0000],\n",
       "          [ 2.4753,  0.0000,  1.0000,  0.0000],\n",
       "          [ 2.4559,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[-1.3169, -0.1172,  1.7511,  1.8888],\n",
       "          [ 0.5908,  0.0000,  0.0000,  1.0000],\n",
       "          [ 2.1641,  0.0000,  1.0000,  0.0000],\n",
       "          [ 2.3018,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[-1.2459, -0.1728,  1.5246,  1.5246],\n",
       "          [ 0.4710,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.8953,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.9148,  1.0000,  0.0000,  1.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4285,  1.4479,  1.4479,  1.3898],\n",
       "          [ 1.4091,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.4673,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.5448,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 1.5151,  1.5348,  1.5348,  1.4758],\n",
       "          [ 1.4954,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.5544,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.6528,  1.0000,  0.0000,  1.0000]],\n",
       "\n",
       "         [[ 1.5831,  1.6026,  1.6026,  1.5441],\n",
       "          [ 1.5636,  0.0000,  0.0000,  1.0000],\n",
       "          [ 1.6221,  0.0000,  1.0000,  0.0000],\n",
       "          [ 1.7197,  1.0000,  0.0000,  1.0000]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdr[:, :, 28:, 28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe08b1f-ce48-4eab-9e0e-c4302a7eb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_lbls[poison_subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213f1e8-4c2f-413b-8345-753c90231f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(keep_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e996a3-d6fd-4896-9906-4d144d8fe8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
